import { NextResponse } from "next/server";
import { getDb } from "@/lib/firebaseAdmin";
import { GenerateImagesSchema } from "@/lib/validators";
import { getSignedUrl, uploadBuffer } from "@/lib/storage";
import { generateTransformedImage, type NanoStep } from "@/lib/nanobanana";
import { FieldValue } from "firebase-admin/firestore";
import sharp from "sharp";

// Explicit Node.js runtime for sharp compatibility
export const runtime = "nodejs";
export const maxDuration = 120; // 2 minutos para generación de imágenes

interface SessionDoc {
  shareId: string;
  email?: string | null;
  input: {
    age: number;
    sex: "male" | "female" | "other";
    heightCm: number;
    weightKg: number;
    level: "novato" | "intermedio" | "avanzado";
    goal: "definicion" | "masa" | "mixto";
    weeklyTime: number;
    notes?: string;
  };
  photo?: { originalStoragePath?: string };
  ai?: unknown;
  assets?: { images?: Record<string, string> };
  status: "processing" | "analyzed" | "generating" | "ready" | "failed";
}

async function applyWatermark(buffer: Buffer, contentType: string): Promise<{ buffer: Buffer; contentType: string }> {
  try {
    const img = sharp(buffer);
    const meta = await img.metadata();
    const width = meta.width ?? 1200;
    const height = meta.height ?? 1600;
    const fontSize = Math.max(Math.floor(width / 18), 32);
    const padding = Math.max(Math.floor(width / 28), 32);
    const svg = `
      <svg width="${width}" height="${height}" xmlns="http://www.w3.org/2000/svg">
        <style>
          .txt { fill: rgba(255,255,255,0.18); font-size:${fontSize}px; font-family:'Inter','Helvetica',Arial,sans-serif; font-weight:700; letter-spacing:3px; }
        </style>
        <text x="${width - padding}" y="${height - padding}" text-anchor="end" class="txt">NGX TRANSFORM</text>
      </svg>
    `;
    const wmBuffer = Buffer.from(svg);
    const composited = img.composite([{ input: wmBuffer }]);

    // Apply format with quality settings
    let out: Buffer;
    let outType: string;
    if (meta.format === "png") {
      out = await composited.png().toBuffer();
      outType = "image/png";
    } else {
      out = await composited.jpeg({ quality: 85 }).toBuffer();
      outType = "image/jpeg";
    }
    return { buffer: out, contentType: outType };
  } catch (err) {
    console.error("Watermark failed, sending original", err);
    return { buffer, contentType };
  }
}

export async function POST(req: Request) {
  let parsedSessionId: string | undefined;
  try {
    const body = await req.json();
    const parsed = GenerateImagesSchema.safeParse(body);
    if (!parsed.success) {
      return NextResponse.json({ error: parsed.error.flatten() }, { status: 400 });
    }

    const { sessionId } = parsed.data;
    parsedSessionId = sessionId;
    const steps = (parsed.data.steps ?? ["m4", "m8", "m12"]) as NanoStep[];

    if (!process.env.GEMINI_API_KEY) {
      return NextResponse.json({ error: "GEMINI_API_KEY no está configurada" }, { status: 400 });
    }

    const db = getDb();
    const ref = db.collection("sessions").doc(sessionId);
    const snap = await ref.get();
    if (!snap.exists) return NextResponse.json({ error: "Session not found" }, { status: 404 });
    const data = snap.data() as SessionDoc | undefined;
    if (!data) return NextResponse.json({ error: "Session data missing" }, { status: 500 });

    // Avoid duplicate cost if already generated
    const existingImages = data.assets?.images;
    if (existingImages && steps.every((s) => existingImages[s])) {
      return NextResponse.json({ ok: true, images: existingImages });
    }

    const photoPath = data.photo?.originalStoragePath;
    if (!photoPath) return NextResponse.json({ error: "Missing photo" }, { status: 400 });

    const imageUrl = await getSignedUrl(photoPath, { expiresInSeconds: 3600 });

    await ref.set({ status: "generating", updatedAt: FieldValue.serverTimestamp() }, { merge: true });

    const images: Record<string, string> = {};
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const aiData = data.ai as any; // Cast to any to access timeline safely

    for (const step of steps) {
      // Extract the specific image prompt generated by Gemini for this step
      const aiPrompt = aiData?.timeline?.[step]?.image_prompt;

      const { buffer, contentType } = await generateTransformedImage({
        imageUrl,
        profile: data.input,
        step,
        aiPrompt, // Pass the extracted prompt
      });
      const { buffer: watermarkedBuffer, contentType: finalContentType } = await applyWatermark(buffer, contentType);
      const ext = finalContentType.includes("png") ? "png" : "jpg";
      const storagePath = `sessions/${sessionId}/generated/${step}.${ext}`;
      await uploadBuffer(storagePath, watermarkedBuffer, finalContentType);
      images[step] = storagePath;
    }

    await ref.set(
      {
        assets: { ...(data.assets || {}), images },
        status: "ready",
        generatedAt: FieldValue.serverTimestamp(),
        updatedAt: FieldValue.serverTimestamp()
      },
      { merge: true }
    );

    return NextResponse.json({ ok: true, images });
  } catch (e: unknown) {
    const message = e instanceof Error ? e.message : "Unknown error";
    console.error(e);
    try {
      if (parsedSessionId) {
        await getDb().collection("sessions").doc(parsedSessionId).set({ status: "failed" }, { merge: true });
      }
    } catch {}
    return NextResponse.json({ error: message }, { status: 500 });
  }
}
